{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from MileStone_3_Create_Neural_Network.WillyAlexNet import MyAlexNet\n",
    "from MileStone_3_Create_Neural_Network.WillyNet import WillyNet\n",
    "from MileStone_3_Create_Neural_Network.WillyMnasNet0_5 import MyMnasNet0_5\n",
    "from MileStone_3_Create_Neural_Network.WillysShuffleNet_v2_x1_0 import myShuffleNet_v2_x1_0\n",
    "from torch import optim\n",
    "from torch.nn import NLLLoss\n",
    "import sys\n",
    "% % writefile InitializeModel.py\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "\n",
    "def initializeModel(config):\n",
    "    # ToDo return model from my private zoo\n",
    "    modelName = config[\"model\"]\n",
    "    if modelName == \"MyAlexNet\":\n",
    "        model = MyAlexNet()\n",
    "    elif modelName == \"WillyNet\":\n",
    "        model = WillyNet()\n",
    "    elif modelName == \"WillyMnasNet0_5\":\n",
    "        model = MyMnasNet0_5()\n",
    "    elif modelName == \"WillysShuffleNet_v2_x1_0\":\n",
    "        model = myShuffleNet_v2_x1_0()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Model {modelName} not supported or whatever something else\")\n",
    "\n",
    "    # model = WillyNet()\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=config.get(\"lr\", 1e-2),\n",
    "        momentum=config.get(\"momentum\", 0.5),\n",
    "        weight_decay=config.get('weight_decay', 1e-6),\n",
    "        nesterov=True,\n",
    "    )\n",
    "    criterion = NLLLoss()\n",
    "    le = config['num_iters_per_epoch']\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer,\n",
    "                                             step_size=le,\n",
    "                                             gamma=config.get(\n",
    "                                                 'gamma', 0.9)\n",
    "                                             )\n",
    "    return model, optimizer, criterion, lr_scheduler\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %%writefile CreateTrainer.py\n",
    "from ignite.engine import Engine, Events, create_supervised_evaluator\n",
    "from pathlib import Path\n",
    "import json\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.handlers import ModelCheckpoint, Checkpoint, DiskSaver\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage, ClassificationReport\n",
    "from ignite.contrib.engines.common import save_best_model_by_val_score\n",
    "import torch\n",
    "# from ignite.metrics.precision import Precision\n",
    "# from ignite.metrics.recall import Recall\n",
    "# source https://colab.research.google.com/github/pytorch/ignite/blob/master/assets/tldr/teaser.ipynb#scrollTo=dFglXKeKOgdW\n",
    "\n",
    "\n",
    "def create_trainer(model, optimizer, criterion, lr_scheduler, config, data):\n",
    "    device = config['device']\n",
    "    (train_loader, train_sampler), (valid_loader,\n",
    "                                    valid_sampler), (test_loader, test_sampler) = data\n",
    "    # Define any training logic for iteration update\n",
    "\n",
    "    def train_step(engine, batch):\n",
    "        x, y = batch[0].to(device), batch[1].to(device)\n",
    "        model.train()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def eval_model_on_batch(engine, batch):\n",
    "        \"\"\"\n",
    "        Evaluation of the model on a single batch\n",
    "\n",
    "        Args:\n",
    "            engine: ignite.engine.Engine\n",
    "            batch: tuple contains the training sample and their labels\n",
    "\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            data, target = batch\n",
    "            y_pred = model(data.to(device))\n",
    "            return y_pred, target.to(device)\n",
    "\n",
    "    trainer = Engine(train_step)\n",
    "    # train_evaluator = Engine(eval_model_on_batch)\n",
    "    # validation_evaluator = Engine(eval_model_on_batch)\n",
    "    # test_evaluator = Engine(eval_model_on_batch)\n",
    "\n",
    "    evaluator = create_supervised_evaluator(\n",
    "        model,\n",
    "        metrics={\"accuracy\": Accuracy(),\n",
    "                 #  \"loss\": RunningAverage(Accuracy()),\n",
    "                 #  \"precision\": Precision(average=False),\n",
    "                 #  'recall': Recall(average=False),\n",
    "                 #            'cr': ClassificationReport(output_dict=True, is_multilabel=False)\n",
    "                 },\n",
    "        device=config.get('device', 'cpu')\n",
    "    )\n",
    "    # evaluatorF1 = create_supervised_evaluator(\n",
    "    #     model, metrics={'cr': ClassificationReport(output_dict=True, is_multilabel=False)\n",
    "    #                     },\n",
    "    #     device=config.get('device', 'cpu')\n",
    "    # )\n",
    "\n",
    "    @trainer.on(Events.ITERATION_COMPLETED(every=10))\n",
    "    def save_checkpoint():\n",
    "        fp = Path(config.get(\"output_path\", \"./output\")) / \"checkpoint.pt\"\n",
    "        torch.save(model.state_dict(), fp)\n",
    "\n",
    "    pbar = ProgressBar(persist=True, bar_format=\"\")\n",
    "\n",
    "    # Run model evaluation every 3 epochs and show results\n",
    "    @trainer.on(Events.EPOCH_COMPLETED(every=1))\n",
    "    def evaluate_model():\n",
    "        state = evaluator.run(valid_loader)\n",
    "        metrics = state.metrics\n",
    "    #     # acc = metrics['accuracy']\n",
    "    #     # loss = metrics['loss']\n",
    "    #     # train_evaluator.run(train_loader)\n",
    "    #     # validation_evaluator.run(valid_loader)\n",
    "\n",
    "    # @trainer.on(Events.EPOCH_COMPLETED(every=5))\n",
    "    # def F1ScoreEval(engine):\n",
    "    #     state = evaluatorF1.run(valid_loader)\n",
    "    #     toPrint = \"\"\n",
    "    #     res_dic = state.metrics['cr']\n",
    "    #     for idx, key in enumerate(res_dic):\n",
    "    #         temp = \"Class: {} f1-score: {:.2f}, \".format(\n",
    "    #             key, res_dic[key]['f1-score'])\n",
    "    #         if idx == 4 or idx == 8 or idx == 12 or idx == 16:\n",
    "    #             toPrint += '\\n'\n",
    "    #         if key == 'macro avg':\n",
    "    #             temp = \"\\nMacro Average:\\nPrecision: {:.3f}, Recall: {:.3f}, F1 {:.3f}\".format(\n",
    "    #                 res_dic[key]['precision'], res_dic[key]['recall'], res_dic[key]['f1-score'],)\n",
    "    #         toPrint += temp\n",
    "    #     pbar.log_message(\"Scores:\\n{}\".format(toPrint))\n",
    "\n",
    "    RunningAverage(output_transform=lambda x: x).attach(\n",
    "        trainer, 'loss'\n",
    "    )\n",
    "    # pbar.attach(trainer, ['loss'])\n",
    "    pbar.attach(trainer, output_transform=lambda x: {\"batch loss\": x})\n",
    "\n",
    "    # Accuracy(output_transform=lambda x: x).attach(train_evaluator, 'train_acc')\n",
    "    # Loss(criterion).attach(train_evaluator, 'train_NLLLoss')\n",
    "\n",
    "    # Accuracy(output_transform=lambda x: x).attach(\n",
    "    #     validation_evaluator, 'val_acc')\n",
    "    # Loss(criterion).attach(validation_evaluator, 'val_NLLLoss')\n",
    "\n",
    "    # checkpointer = ModelCheckpoint(\n",
    "    #     config.get('checkpointPath', './tmp/models'), config.get('model',\n",
    "    #                                                              'Unknown_you_lazy_bastart'),\n",
    "    #     n_saved=config.get('max_saved_checkout', 1), create_dir=True,\n",
    "    #     save_as_state_dict=True, require_empty=config.get('require_empty', True)\n",
    "    # )\n",
    "    # trainer.add_event_handler(Events.EPOCH_COMPLETED(every=3),\n",
    "    #                           checkpointer, {config.get('model'): model}\n",
    "    #                           )\n",
    "\n",
    "    # to_save = {'trainer': trainer,\n",
    "    #            'model': model,\n",
    "    #            'optimizer': optimizer,\n",
    "    #            'lr_scheduler': lr_scheduler,\n",
    "    #            }\n",
    "\n",
    "    # handler = Checkpoint(to_save,\n",
    "    #                      DiskSaver(config['trainer_save_path'],\n",
    "    #                                create_dir=True, require_empty=config['require_empty']\n",
    "    #                                )\n",
    "    #                      )\n",
    "    # bestModelSaver = save_best_model_by_val_score(output_path=config['best_model_path'],\n",
    "    #                                               evaluator=evaluator, model=model,\n",
    "    #                                               metric_name='accuracy',\n",
    "    #                                               n_saved=config.get(\n",
    "    #     \"best_n_saved\", 2)\n",
    "    # )\n",
    "    # evaluator.add_event_handler(Events.EPOCH_COMPLETED, bestModelSaver)\n",
    "\n",
    "    # trainer.add_event_handler(Events.EPOCH_COMPLETED, handler)\n",
    "\n",
    "    # return trainer, train_evaluator, validation_evaluator, test_evaluator, evaluator, pbar\n",
    "    return trainer, evaluator\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%writefile TrainingIgnite.py\n",
    "from InitializeModel import initializeModel\n",
    "from CreateTrainer import create_trainer\n",
    "from getData import getData\n",
    "#from ignite.engine import create_supervised_evaluator, Events\n",
    "# from ignite.metrics import Accuracy, Loss, RunningAverage\n",
    "from ignite.contrib.engines import common\n",
    "# from ignite.handlers import EarlyStopping\n",
    "# from ignite.metrics import ClassificationReport\n",
    "import ignite.distributed as idist\n",
    "# import torch\n",
    "\n",
    "# source https://colab.research.google.com/github/pytorch/ignite/blob/master/assets/tldr/teaser.ipynb#scrollTo=dFglXKeKOgdW\n",
    "# dependenciues\n",
    "\n",
    "# ignite\n",
    "\n",
    "# PyTorch\n",
    "\n",
    "\n",
    "def training(config):\n",
    "    # Setup dataflow and\n",
    "    data = getData(config)\n",
    "    model, optimizer, criterion, lr_scheduler = initializeModel(config)\n",
    "    model.to(config.get('device', 'cpu'))\n",
    "    # Setup model trainer and evaluator\n",
    "    trainer, evaluator = create_trainer(model, optimizer, criterion,\n",
    "                                        lr_scheduler, config, data\n",
    "                                        )\n",
    "    data_loader, _, _ = data\n",
    "    train_loader, train_sampler = data_loader\n",
    "\n",
    "    if config['train_now'] is not True:\n",
    "        return trainer, model, optimizer, criterion, lr_scheduler, train_loader\n",
    "\n",
    "    if idist.get_rank() == 0:\n",
    "        # print('Start logging', config['tensorboard_logger_path'])\n",
    "        tb_logger = common.setup_tb_logging(\n",
    "            output_path=config.get(\"tensorboard_logger_path\", \"output\"),\n",
    "            trainer=trainer, optimizers=optimizer,\n",
    "            evaluators={\"validation\": evaluator,\n",
    "                        # 'cr': evaluator,\n",
    "                        # 'loss': trainer,\n",
    "                        # 'val_NLLLoss': validation_evaluator,\n",
    "                        # 'val_acc': validation_evaluator,\n",
    "                        # 'train_NLLLoss': train_evaluator,\n",
    "                        # 'train_acc': train_evaluator,\n",
    "                        },\n",
    "            log_every_iters=1,\n",
    "        )\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=config.get(\"max_epochs\", 3))\n",
    "\n",
    "    if idist.get_rank() == 0:\n",
    "        # print(\"cloosing tb_logger...\")\n",
    "        tb_logger.close()\n",
    "    # tb_logger.close()\n",
    "    # return trainer, (train_loader, train_sampler), (valid_loader,\n",
    "    #                                                 valid_sampler), (test_loader, test_sampler)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def initConfig(model_name: str) -> dict:\n",
    "    from datetime import date, datetime\n",
    "    datestamp = date.today().strftime(\"%d_%m_%Y\")\n",
    "    timestamp = datetime.now().strftime(\"%H\")\n",
    "    from torch import device\n",
    "    config = {\n",
    "        \"model\": f\"{model_name}\",\n",
    "        \"dataset\": \"Willys\",\n",
    "        'batch_size': 400,\n",
    "        \"valid_procentage\": 0.15,\n",
    "        \"test_procentage\": 0.1,\n",
    "        'data_path': \"../Dataset_Willys_2020/ORGINAL/\",\n",
    "        'output_path': f'./training_files/training_Checkpoints/{model_name}/date_{datestamp}/time_{timestamp}/checkpoints/',\n",
    "        'tensorboard_logger_path': f'./training_files/tensorboard/{model_name}/date_{datestamp}/time_{timestamp}/log',\n",
    "        'device': device('cuda:0'),\n",
    "        'checkpointPath': f'./training_files/training_Checkpoints/{model_name}/date_{datestamp}/time_{timestamp}/checkpoints/',\n",
    "        \"require_empty\": False,\n",
    "        \"max_epochs\": 15,\n",
    "        \"lr\": 1e-2,\n",
    "        \"momentum\": 0.5,\n",
    "        \"weight_decay\": 1e-6,\n",
    "        \"gamma\": 0.9,\n",
    "        \"best_model_path\": f'./training_files/bestModels/{model_name}/date_{datestamp}/time_{timestamp}/bestModel/',\n",
    "        'trainer_save_path': f'./training_files/training_Checkpoints/{model_name}/date_{datestamp}/time_{timestamp}/trainer/',\n",
    "        'train_now': True\n",
    "    }\n",
    "    return config\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "modelNamesDict = {'AlexNet': \"MyAlexNet\",\n",
    "                  'MustafaNet': \"WillyNet\",\n",
    "                  'MnasNet0_5': \"WillyMnasNet0_5\",\n",
    "                  'ShuffleNet_V2_x1_0': \"WillysShuffleNet_v2_x1_0\",\n",
    "                  }\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %reload_ext tensorboard\n",
    "%load_ext tensorboard\n",
    "# %tensorboard - -logdir = config['tensorboard_logger_path']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from TrainingIgnite import training\n",
    "config = initConfig(modelNamesDict['MnasNet0_5'])\n",
    "config[\"max_epochs\"] = 10\n",
    "config[\"train_now\"] = True\n",
    "print(config[\"model\"], config['train_now'])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "training(config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from CreateTrainer import create_trainer\n",
    "# trainer, train_evaluator, validation_evaluator, test_evaluator, evaluator, pbar \n",
    "# Setup model trainer and evaluator\n",
    "whatever = create_trainer(model, optimizer, criterion, lr_scheduler, config, data)\n",
    "len(whatever)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setup model trainer and evaluator\n",
    "trainer, train_evaluator, validation_evaluator, test_evaluator, evaluator, pbar = create_trainer(\n",
    "    model, optimizer, criterion, lr_scheduler, config, data\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer, model, optimizer, criterion, lr_scheduler, train_loader = training(\n",
    "    config)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "to_load = {'trainer': trainer, 'model': model,\n",
    "           'optimizer': optimizer, 'lr_scheduler': lr_scheduler}\n",
    "checkpoint = torch.load(config['trainer_save_path']+'checkpoint_90.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from ignite.handlers import Checkpoint\n",
    "Checkpoint.load_objects(to_load=to_load, checkpoint=checkpoint)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer.run(train_loader,max_epochs=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test = {\"0\": {\"precision\": 0.0, \"recall\": 0.0, \"f1-score\": 0.0}, \"1\": {\"precision\": 0.5813953488372093, \"recall\": 0.5434782608695652, \"f1-score\": 0.5617977528089882}, \"2\": {\"precision\": 0.0, \"recall\": 0.0, \"f1-score\": 0.0}, \"3\": {\"precision\": 0.2714285714285714, \"recall\": 0.3392857142857143, \"f1-score\": 0.30158730158730107}, \"4\": {\"precision\": 0.4794520547945205, \"recall\": 0.42168674698795183, \"f1-score\": 0.44871794871794823}, \"5\": {\"precision\": 0.208955223880597, \"recall\": 0.2222222222222222, \"f1-score\": 0.21538461538461487}, \"6\": {\"precision\": 0.75, \"recall\": 0.16666666666666666, \"f1-score\": 0.27272727272727243}, \"7\": {\"precision\": 0.5263157894736842, \"recall\": 0.2857142857142857, \"f1-score\": 0.3703703703703699}, \"8\": {\"precision\": 0.3111111111111111, \"recall\": 0.3218390804597701, \"f1-score\": 0.3163841807909599}, \"9\": {\"precision\": 0.2975206611570248,\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \"recall\": 0.576, \"f1-score\": 0.392370572207084}, \"10\": {\"precision\": 0.47297297297297297, \"recall\": 0.5511811023622047, \"f1-score\": 0.5090909090909086}, \"11\": {\"precision\": 0.42105263157894735, \"recall\": 0.4, \"f1-score\": 0.41025641025640974}, \"12\": {\"precision\": 0.4117647058823529, \"recall\": 0.42857142857142855, \"f1-score\": 0.4199999999999995}, \"13\": {\"precision\": 0.4308510638297872, \"recall\": 0.574468085106383, \"f1-score\": 0.49240121580547064}, \"14\": {\"precision\": 0.6923076923076923, \"recall\": 0.28378378378378377, \"f1-score\": 0.40255591054313056}, \"15\": {\"precision\": 0.0, \"recall\": 0.0, \"f1-score\": 0.0}, \"16\": {\"precision\": 0.0, \"recall\": 0.0, \"f1-score\": 0.0}, \"17\": {\"precision\": 0.0, \"recall\": 0.0, \"f1-score\": 0.0}, \"macro avg\": {\"precision\": 0.3252848792919151, \"recall\": 0.28416096539055424, \"f1-score\": 0.2840913589050254}}\n",
    "print(type(test))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer = create_trainer(model, optimizer, criterion, lr_scheduler, config)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torchinfo\n",
    "import torch\n",
    "from MileStone_3_Create_Neural_Network.WillyAlexNet import MyAlexNet\n",
    "#willyAlexNet = MyAlexNet()\n",
    "model = MyAlexNet()\n",
    "device = torch.device('cuda:0')\n",
    "model.to(device)\n",
    "print(model)\n",
    "args = {\"lr\": 0.01, \"momentum\":0.5, \"epochs\": 5, \"log_interval\": 3 }\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=args[\"lr\"], momentum = args[\"momentum\"])\n",
    "# optimizer = optim.AdamW(model.parameters(), weight_decay=1e-6)\n",
    "criterion = torch.nn.NLLLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Single operation step when training\n",
    "def train_one_step(engine, batch):\n",
    "    \"\"\"\n",
    "    Single operation step when training\n",
    "\n",
    "    Args:\n",
    "        engine: ignite.engine.Engine\n",
    "        batch: tuple contains the training sample and their labels\n",
    "    \"\"\"\n",
    "    model.train(True)\n",
    "    optimizer.zero_grad()\n",
    "    data, target = batch\n",
    "    output = model(data.to(device))\n",
    "    loss = criterion(output, target.to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def eval_model_on_batch(engine, batch):\n",
    "    \"\"\"\n",
    "    Evaluation of the model on a single batch\n",
    "\n",
    "    Args:\n",
    "        engine: ignite.engine.Engine\n",
    "        batch: tuple contains the training sample and their labels\n",
    "\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data, target = batch\n",
    "        y_pred = model(data.to(device))\n",
    "        \n",
    "        return y_pred, target.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer = Engine(train_one_step)\n",
    "train_evaluator = Engine(eval_model_on_batch)\n",
    "validation_evaluator = Engine(eval_model_on_batch)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "RunningAverage(output_transform=lambda x: x).attach(trainer,'loss')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Accuracy(output_transform=lambda x: x).attach(train_evaluator,'accuracy')\n",
    "Loss(criterion).attach(train_evaluator, 'NLLLoss')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Accuracy(output_transform=lambda x: x).attach(validation_evaluator,'accuracy')\n",
    "Loss(criterion).attach(validation_evaluator, 'NLLLoss')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pbar = ProgressBar(persist=True, bar_format=\"\")\n",
    "pbar.attach(trainer,['loss'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['NLLLoss']\n",
    "    return -val_loss\n",
    "\n",
    "handler_earlyStopping = EarlyStopping(patience=5, score_function=score_function, trainer=trainer)\n",
    "validation_evaluator.add_event_handler(Events.COMPLETED,handler_earlyStopping)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    train_evaluator.run(train_loader)\n",
    "    metrics = train_evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_nll_loos = metrics['NLLLoss']\n",
    "    pbar.log_message(\n",
    "        \"Training Results - Epoch: {} Avg accuracy: {:.2f} avg loss {:.2f}\".format(engine.state.epoch, avg_accuracy,\n",
    "       avg_nll_loos)\n",
    "       )\n",
    "\n",
    "def log_validation_results(engine):\n",
    "    validation_evaluator.run(valid_loader)\n",
    "    metrics = validation_evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_nll_loos = metrics['NLLLoss'] \n",
    "    pbar.log_message\n",
    "    (\n",
    "        \"Training Results - Epoch: {} Avg accuracy: {:.2f} avg loss {:.2f}\".format(engine.state.epoch, avg_accuracy, avg_nll_loos)\n",
    "    )\n",
    "    pbar.n = pbar.last_print_n = 0\n",
    "\n",
    "\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, log_validation_results)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "checkpointer = ModelCheckpoint('./tmp/models', 'willyAlexNet', n_saved=2, create_dir=True, save_as_state_dict=True)\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpointer, {'willyAlexNet': model})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer.run(train_loader, max_epochs=30)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def create_trainer(model, optimizer, criterion, lr_scheduler, config):\n",
    "    device = config['device']\n",
    "    # Define any training logic for iteration update\n",
    "\n",
    "    def train_step(engine, batch):\n",
    "        x, y = batch[0].to(device), batch[1].to(device)\n",
    "        model.train()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    # Define trainer engine\n",
    "    trainer = Engine(train_step)\n",
    "\n",
    "    @trainer.on(Events.ITERATION_COMPLETED(every=3))\n",
    "    def save_checkpoint():\n",
    "        fp = Path(config.get(\"output_path\", \"output\")) / \"checkpoint.pt\"\n",
    "        torch.save(model.state_dict(), fp)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(engine):\n",
    "        train_evaluator.run(train_loader)\n",
    "        metrics = train_evaluator.state.metrics\n",
    "        avg_accuracy = metrics['accuracy']\n",
    "        avg_nll_loos = metrics['NLLLoss']\n",
    "        pbar.log_message(\n",
    "            \"Training Results - Epoch: {} Avg accuracy: {:.2f} avg loss {:.2f}\".format(engine.state.epoch, avg_accuracy,\n",
    "                                                                                       avg_nll_loos)\n",
    "        )\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(engine):\n",
    "        validation_evaluator.run(valid_loader)\n",
    "        metrics = validation_evaluator.state.metrics\n",
    "        avg_accuracy = metrics['accuracy']\n",
    "        avg_nll_loos = metrics['NLLLoss']\n",
    "        pbar.log_message\n",
    "        (\n",
    "            \"Training Results - Epoch: {} Avg accuracy: {:.2f} avg loss {:.2f}\".format(\n",
    "                engine.state.epoch, avg_accuracy, avg_nll_loos)\n",
    "        )\n",
    "        pbar.n = pbar.last_print_n = 0\n",
    "\n",
    "    # Add progress bar showing batch loss value\n",
    "    ProgressBar().attach(trainer, output_transform=lambda x: {\"batch loss\": x})\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        config.get('checkpointPath', './tmp/models'), config.get('model',\n",
    "                                                                 'Unknown_you_lazy_bastart'),\n",
    "        n_saved=config.get('max_saved_checkout', 2), create_dir=True,\n",
    "        save_as_state_dict=True\n",
    "    )\n",
    "    trainer.add_event_handler(Events.EPOCH_COMPLETED,\n",
    "                              checkpointer, {config.get('model'): model}\n",
    "                              )\n",
    "\n",
    "    return trainer\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from MileStone_3_Create_Neural_Network.WillyAlexNet import MyAlexNet\n",
    "import torch\n",
    "\n",
    "\n",
    "def initalizeModel(config):\n",
    "    # ToDo return model from my private zoo\n",
    "    model = MyAlexNet()\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=config.get(\"lr\", 1e-2),\n",
    "        momentum=config.get(\"momentum\", 0.5),\n",
    "        weight_decay=config.get('weight_decay', 1e-6),\n",
    "        nesterov=True,\n",
    "    )\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    le = config['num_iter_per_epoch']\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer,\n",
    "                                                   step_size=le,\n",
    "                                                   gamma=config.get(\n",
    "                                                       'gamma', 0.9)\n",
    "                                                   )\n",
    "    return model, optimizer, criterion, lr_scheduler\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torchinfo\n",
    "config = {\n",
    "    \"model\": \"MyAlexNet\",\n",
    "    \"dataset\": \"Willys\",\n",
    "    'batch_size': 400,\n",
    "    \"num_iter_per_epoch\": len(train_loader),\n",
    "    'data_path': \"../Dataset_Willys_2020/ORGINAL/\",\n",
    "    'output_path': './tmp/output/test',\n",
    "    'device': torch.device('cuda:0')\n",
    "}\n",
    "model, optimizer, criterion, lr_scheduler = initalizeModel(config=config)\n",
    "torchinfo.summary(model);\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer = create_trainer(model, optimizer, criterion, lr_scheduler, config)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "Path(config.get('data_path', \"dd\")) / \"checkpointer.pt\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torchinfo\n",
    "import torch\n",
    "from MileStone_3_Create_Neural_Network.WillyAlexNet import MyAlexNet\n",
    "#willyAlexNet = MyAlexNet()\n",
    "model = MyAlexNet()\n",
    "device = torch.device('cuda:0')\n",
    "model.to(device)\n",
    "print(model)\n",
    "args = {\"lr\": 0.01, \"momentum\":0.5, \"epochs\": 5, \"log_interval\": 3 }\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=args[\"lr\"], momentum = args[\"momentum\"])\n",
    "# optimizer = optim.AdamW(model.parameters(), weight_decay=1e-6)\n",
    "criterion = torch.nn.NLLLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torchinfo\n",
    "import torch\n",
    "from MileStone_3_Create_Neural_Network.WillyAlexNet import MyAlexNet\n",
    "#willyAlexNet = MyAlexNet()\n",
    "model = MyAlexNet()\n",
    "device = torch.device('cuda:0')\n",
    "model.to(device)\n",
    "print(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch.optim as optim\n",
    "def train(model, device, train_loaderIn, args):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args[\"lr\"], momentum = args[\"momentum\"])\n",
    "    # optimizer = optim.AdamW(model.parameters(), weight_decay=1e-6)\n",
    "    for epoch in range(1, args[\"epochs\"]+1):\n",
    "        train_epoch(epoch=epoch, args=args, model=model,\n",
    "         device=device, data_loader=train_loaderIn, optimizer=optimizer\n",
    "         )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.nn import functional as F\n",
    "def train_epoch(epoch:int, args:dict, model, device, data_loader, optimizer):\n",
    "    model.train(True)\n",
    "    pid = os.getpid()\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.to(device))\n",
    "        # output_pred = F.log_softmax(output,dim=1)\n",
    "        loss = F.nll_loss(output, target.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            print(\"{}\\tTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                pid, epoch, batch_idx * len(data), len(data_loader.dataset),\n",
    "                100. * batch_idx / len(data_loader), loss.item()\n",
    "                ) \n",
    "            )\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def test(model, device, test_loaderIn):\n",
    "    test_epoch(model=model, device=device,data_loader=test_loaderIn)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def test_epoch(model, device, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            output = model(data.to(device))\n",
    "            # output_pred = F.log_softmax(output,dim=1)\n",
    "            test_loss += F.nll_loss(output, target.to(device),reduction='sum').item()\n",
    "            pred = output.max(1)[1]\n",
    "            correct += pred.eq(target.to(device)).sum().item()\n",
    "\n",
    "    test_loss /=  len(data_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset))\n",
    "        )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#import the model\n",
    "from MileStone_3_Create_Neural_Network.WillyNet import WillyNet\n",
    "import torch\n",
    "assert torch.cuda.is_available()\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "willy = WillyNet()\n",
    "from torchinfo import summary\n",
    "summary(willy)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "args = {\"lr\": 0.01, \"momentum\":0.5, \"epochs\": 5, \"log_interval\": 3 }\n",
    "device = torch.device('cuda:0')\n",
    "willy.to(device)\n",
    "willy.share_memory()\n",
    "train(model=willy, device=device, train_loader=train_loader,args=args)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test(model=willy, device=device, test_loader=train_loader)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def train(rank, args, model, device, dataset, dataloader_kwargs):\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, **dataloader_kwargs)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr,\n",
    "                          momentum=args.momentum)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train_epoch(epoch, args, model, device, train_loader, optimizer)\n",
    "\n",
    "\n",
    "def test(args, model, device, dataset, dataloader_kwargs):\n",
    "    torch.manual_seed(args.seed)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset, **dataloader_kwargs)\n",
    "    test_epoch(model, device, test_loader)\n",
    "\n",
    "\n",
    "def train_epoch(epoch, args, model, device, data_loader, optimizer):\n",
    "    model.train()\n",
    "    pid = os.getpid()\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.to(device))\n",
    "        loss = F.nll_loss(output, target.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('{}\\tTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                pid, epoch, batch_idx * len(data), len(data_loader.dataset),\n",
    "                100. * batch_idx / len(data_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "\n",
    "def test_epoch(model, device, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            output = model(data.to(device))\n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output, target.to(device),\n",
    "                                    reduction='sum').item()\n",
    "            pred = output.max(1)[1]  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.to(device)).sum().item()\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('umu-pytorch': conda)"
  },
  "interpreter": {
   "hash": "52604bc78b09674e91f4fa9bc994d961bb2ba050c8b816e2c0e907b2766bc32f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}